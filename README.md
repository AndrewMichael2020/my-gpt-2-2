# Healthcare SQL Agent - Model-First MVP

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/AndrewMichael2020/my-gpt-2-2/blob/main/colab_train.ipynb)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-ee4c2c.svg)](https://pytorch.org/)

A complete end-to-end pipeline for training a decoder-only language model from scratch to generate safe, validated T-SQL SELECT queries for healthcare analytics.

## ğŸš€ Quick Start

Click the "Open in Colab" badge above to launch the notebook directly in Google Colab, then:

1. Select Runtime â†’ Change runtime type â†’ GPU (T4, L4, or better)
2. Run all cells sequentially

The notebook will:
- Generate 5,000+ training samples with synthetic SQL queries
- Train a BPE tokenizer (8k vocab)
- Train a tiny decoder-only transformer (~50M parameters)
- Run inference on 3 test questions
- Validate outputs against strict SQL rules

### What Gets Built

The pipeline creates:

| Component | Description | Output |
|-----------|-------------|--------|
| **Schema** | Healthcare database with 5 tables (Patients, Visits, Departments, Providers, Diagnoses) | `data/example_schema.json` |
| **Dataset** | Synthetic T-SQL training data with placeholders for IDs/dates | `data/train.jsonl` (5k samples)<br>`data/val.jsonl` (200 samples) |
| **Tokenizer** | BPE tokenizer trained on SQL corpus | `artifacts/tokenizer/tokenizer.json` |
| **Model** | Tiny decoder-only transformer (512d, 8 layers, 8 heads) | `checkpoints/checkpoint_epoch_*.pt` |
| **Validation** | SELECT-only, schema-aware, placeholder-safe gates | Built-in validation functions |

## ğŸ“‹ Pipeline Overview

### 1. Schema Definition
Healthcare analytics schema with:
- **Patients**: PatientID, demographics, insurance
- **Visits**: VisitID, dates, charges, provider/department links
- **Departments**: DepartmentID, names, locations
- **Providers**: ProviderID, specialty, department
- **Diagnoses**: DiagnosisID, ICD codes, visit links

### 2. Dataset Generation
Deterministic SQL templates for:
- **Aggregations**: COUNT, SUM, AVG
- **Grouping**: By month, day, department, provider
- **Filtering**: WHERE with ID and date placeholders
- **Joins**: Multi-table queries with patient/department data

Each sample includes:
```json
{
  "schema_text": "Patients(PatientID, FirstName, ...); Visits(...); ...",
  "question": "How many visits did patient __ID_1__ have?",
  "id_map": "__ID_1__=5432",
  "sql": "SELECT COUNT(*) FROM Visits WHERE PatientID = __ID_1__;"
}
```

### 3. ID Placeholder System
**Why placeholders?**
- Healthcare queries contain exact IDs that must not be corrupted
- Model learns SQL structure without memorizing fragile identifiers
- Deterministic extraction â†’ placeholder replacement â†’ validation â†’ reinjection

**Flow:**
1. Extract IDs/dates from question: `"patient 5432"` â†’ `__ID_1__`
2. Train model on placeholders
3. Validate placeholder integrity in generated SQL
4. Reinject exact values: `__ID_1__` â†’ `5432`

### 4. Model Architecture
Decoder-only transformer optimized for Colab L4:
- **Parameters**: ~50M (MVP) â†’ 300M (production target)
- **Layers**: 8 transformer blocks
- **Dimensions**: 512d embeddings, 8 attention heads
- **Context**: 512 token max sequence length
- **Training**: FP16, gradient checkpointing, causal masking

### 5. Validation Gates
Generated SQL must pass ALL checks:
- âœ“ Exactly one statement ending with `;`
- âœ“ SELECT-only (no DML/DDL)
- âœ“ Schema-known tables only
- âœ“ Valid placeholders from ID map
- âœ“ No forbidden keywords (INSERT, DROP, EXEC, etc.)

### 6. Training Strategy
**MVP (this notebook):**
- 5k samples, 3 epochs, ~10 minutes on L4
- Goal: Prove pipeline works end-to-end

**Production scaling:**
- 200k-800k samples
- ~300M parameter model
- Multi-session training with checkpointing
- Advanced templates (subqueries, HAVING, complex joins)

## ğŸ¯ Acceptance Criteria

âœ… **Dataset**: Generate â‰¥5,000 training samples with deterministic SQL templates  
âœ… **Tokenizer**: Train BPE tokenizer on SQL corpus  
âœ… **Model**: Train tiny decoder-only model (~50M params)  
âœ… **Inference**: Generate SQL for 3 example questions  
âœ… **Validation**: â‰¥2/3 questions pass strict validation gates  
âœ… **Placeholders**: Exact ID reinjection with integrity checks  

## ğŸ“Š Example Output

```
[Question 1]
Original: How many visits did patient 5432 have in department 25?
Clean: How many visits did patient __ID_1__ have in department __ID_2__?
ID Map: {'__ID_1__': '5432', '__ID_2__': '25'}

Generated SQL (with placeholders):
  SELECT COUNT(*) FROM Visits WHERE PatientID = __ID_1__ AND DepartmentID = __ID_2__;

âœ“ Validation: PASSED

Final SQL (with real IDs):
  SELECT COUNT(*) FROM Visits WHERE PatientID = 5432 AND DepartmentID = 25;
```

## ğŸ”§ Technical Details

### Dependencies
Installed automatically in notebook:
- PyTorch â‰¥2.0 (core training)
- Transformers â‰¥4.35 (utilities)
- Tokenizers â‰¥0.15 (BPE training)
- Standard: numpy, tqdm, jsonlines

### Compute Requirements
- **GPU**: T4/L4 (16-22GB VRAM) minimum
- **RAM**: ~16GB
- **Disk**: ~5GB for checkpoints
- **Time**: ~10 minutes for MVP, ~2 hours for scaled training

### Model Scaling Path
| Size | Params | Layers | d_model | Heads | VRAM | Target |
|------|--------|--------|---------|-------|------|--------|
| Tiny | 50M | 8 | 512 | 8 | ~2GB | MVP proof |
| Small | 300M | 12 | 768 | 12 | ~6GB | Production |
| Medium | 700M | 16 | 1024 | 16 | ~14GB | Stretch goal |

## ğŸ“ File Structure

```
.
â”œâ”€â”€ colab_train.ipynb          # ğŸ¯ MAIN NOTEBOOK - Run this!
â”œâ”€â”€ README.md                   # This file
â”œâ”€â”€ STRATEGY (2).md            # Model-first strategy document
â”œâ”€â”€ README_IDEAL_STATE (1).md  # Target architecture specification
â”‚
â””â”€â”€ (Generated at runtime)
    â”œâ”€â”€ data/
    â”‚   â”œâ”€â”€ example_schema.json
    â”‚   â”œâ”€â”€ train.jsonl
    â”‚   â””â”€â”€ val.jsonl
    â”œâ”€â”€ artifacts/
    â”‚   â””â”€â”€ tokenizer/
    â”‚       â””â”€â”€ tokenizer.json
    â””â”€â”€ checkpoints/
        â””â”€â”€ checkpoint_epoch_*.pt
```

## ğŸš¦ Next Steps

After MVP validation:

1. **Scale dataset**: 5k â†’ 200k+ samples
2. **Add templates**: Subqueries, HAVING, window functions, CTEs
3. **Scale model**: 50M â†’ 300M parameters
4. **Advanced training**: Learning rate scheduling, mixed precision
5. **Evaluation**: Held-out test set with accuracy metrics
6. **CLI tool**: `python -m sql_agent --schema ... "question"`
7. **Schema expansion**: Multi-schema support, dynamic schema loading

## ğŸ“ License

MIT License - See LICENSE file

## ğŸ¤ Contributing

This is an MVP proof-of-concept. For production use:
- Add comprehensive test coverage
- Implement beam search/nucleus sampling
- Add SQL execution safety checks
- Build evaluation harness with metrics
- Deploy as API service

---

**Status**: âœ… MVP Complete - Ready for Colab testing